{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is some of the ideas from https://www.kaggle.com/c/LANL-Earthquake-Prediction/discussion/94433#latest-561517. Solution is based on my own features as it wasn't described all of the features in discussion. Hence it scored 2.42174 on private score (instead of original solution 2.29978 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import random as rand\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_absolute_error \n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "\n",
    "import os\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,BatchNormalization,Dropout\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import adam\n",
    "\n",
    "from tsfresh.feature_extraction import feature_calculators\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import pywt\n",
    "\n",
    "import librosa\n",
    "\n",
    "from scipy.signal import find_peaks,peak_prominences\n",
    "from scipy.stats import boxcox\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_X = pd.read_csv(\"../../extracted_feat/train_x_55_cols.csv\")\n",
    "test_df = pd.read_csv(\"../../extracted_feat/test_55_cols.csv\",index_col=\"Unnamed: 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_y = pd.read_csv(\"../../extracted_feat/train_y_58.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 µs, sys: 0 ns, total: 4 µs\n",
      "Wall time: 10.3 µs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "train_df = pd.read_csv(os.path.join(\"../../input\",'train.csv'), dtype={'acoustic_data': np.int16, 'time_to_failure': np.float32})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# def denoise_signal_simple(x, wavelet='db4', level=1):\n",
    "#     coeff = pywt.wavedec(x, wavelet, mode=\"per\")\n",
    "#     #univeral threshold\n",
    "#     uthresh = 10\n",
    "#     coeff[1:] = (pywt.threshold(i, value=uthresh, mode='hard') for i in coeff[1:])\n",
    "#     # Reconstruct the signal using the thresholded coefficients\n",
    "#     return pywt.waverec(coeff, wavelet, mode='per')\n",
    "# def create_features(seg_id,seg, X):\n",
    "#     xc = seg[\"acoustic_data\"]\n",
    "    \n",
    "#     x_roll_std = xc.rolling(1000).std().dropna().values\n",
    "#     for i in [0.7,0.75,0.8,0.85,0.9,1.0,1.5,1.75,2.0,2.25,2.5]:\n",
    "#         peaks, h = find_peaks(x_roll_std, height=[i], distance=2000)\n",
    "#         if(h['peak_heights'].shape[0]>1):\n",
    "#             X_tr.loc[segment, 'peaks_count_' + str(i)] = h['peak_heights'].shape[0]\n",
    "#             X_tr.loc[segment, 'peaks_mean_' + str(i)] = h['peak_heights'].mean()\n",
    "#             X_tr.loc[segment, 'peaks_std_' + str(i)] = h['peak_heights'].std()\n",
    "#             X_tr.loc[segment, 'peaks_max_' + str(i)] = h['peak_heights'].max()\n",
    "#             X_tr.loc[segment, 'peaks_min_' + str(i)] = h['peak_heights'].min()\n",
    "#             #Peak prominences\n",
    "#             prominences = peak_prominences(x_roll_std, peaks)[0]\n",
    "#             contour_heights = x_roll_std[peaks] - prominences\n",
    "#             X_tr.loc[segment, 'peaks_prom_mean_' + str(i)] = contour_heights.mean()\n",
    "#             X_tr.loc[segment, 'peaks_prom_std_' + str(i)] = contour_heights.std()\n",
    "#             X_tr.loc[segment, 'peaks_prom_max_' + str(i)] = contour_heights.max()\n",
    "#             X_tr.loc[segment, 'peaks_prom_min_' + str(i)] = contour_heights.min()\n",
    "#             #distance between peaks\n",
    "#             X_tr.loc[segment, 'peaks_dist_mean_' + str(i)] = np.diff(peaks).mean()\n",
    "#             X_tr.loc[segment, 'peaks_dist_std_' + str(i)] = np.diff(peaks).std()\n",
    "#             X_tr.loc[segment, 'peaks_dist_max_' + str(i)] = np.diff(peaks).max()\n",
    "#             X_tr.loc[segment, 'peaks_dist_min_' + str(i)] = np.diff(peaks).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_features_train(train_df,segments,train_X,train_y):\n",
    "    for seg_id in tqdm_notebook(segments):\n",
    "        shift = 0\n",
    "        seg = train_df.iloc[seg_id*rows+shift:seg_id*rows+rows+shift]\n",
    "        create_features(seg_id, seg,train_X)\n",
    "        train_y.loc[seg_id, 'time_to_failure'] = seg['time_to_failure'].values[-1]\n",
    "        \n",
    "        \n",
    "def add_features_test(test_df):\n",
    "    segment_names = [file for file in os.listdir(\"../../input\") if file.startswith(\"seg\")]\n",
    "    for file in tqdm_notebook(segment_names):\n",
    "        seg_id = file[:-4]\n",
    "        segment = pd.read_csv(os.path.join(\"../../input\",file),dtype={'acoustic_data': np.int16})\n",
    "        create_features(seg_id,segment,test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rows = 150000\n",
    "segments = list(range(int((np.floor(train_df.shape[0]))/ rows)))\n",
    "# segments = train_X.index.values\n",
    "#Prepare empty frame\n",
    "test_df = pd.DataFrame(dtype=np.float64)\n",
    "train_X = pd.DataFrame(index=segments, dtype=np.float64)\n",
    "train_y = pd.DataFrame(index=segments, dtype=np.float64, columns=['time_to_failure'])\n",
    "# print(\"Number of segments: \", len(segments))\n",
    "add_features_train(train_df,segments,train_X,train_y)\n",
    "add_features_test(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(train_X)\n",
    "train_X_scaled = pd.DataFrame(scaler.transform(train_X), columns=train_X.columns)\n",
    "test_scaled = pd.DataFrame(scaler.transform(test_df), columns=test_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eq = (train_y[\"time_to_failure\"].diff() > 0.5)\n",
    "eq_groups_data = pd.DataFrame(index=train_y.index)\n",
    "eq_groups_data[\"earthquake\"] = 0 \n",
    "eq_groups_data.loc[eq,\"earthquake\"] = 1\n",
    "eq_groups_data[\"earthquake\"]=eq_groups_data[\"earthquake\"].cumsum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_experiments = [\n",
    "    [1,2,4,7,9,10,11,12,14],[1,2,4,7,8,9,10,11,14],[1,2,4,7,10,11,14],[1,3,7,10,11,14]\n",
    "                    ]\n",
    "subtrain_X = train_X_scaled[eq_groups_data[\"earthquake\"].isin(train_experiments[0])].reset_index(drop=True)\n",
    "# sns.distplot(subtrain_X[\"rollingMean200_num_peaks_10\"])\n",
    "# sns.distplot(test_scaled[\"rollingMean200_num_peaks_10\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sns.distplot(subtrain_X['peak_duration_mean'])\n",
    "# sns.distplot(test_scaled['peak_duration_mean'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_lgb(X_val,y_val,X_train,y_train,params):\n",
    "    model = lgb.LGBMRegressor(**params, n_estimators = 20000,n_jobs=-1)\n",
    "    model.fit(X_train,y_train,\n",
    "                  eval_set=[(X_val,y_val),(X_train,y_train)], \n",
    "                  verbose=5000,\n",
    "                  early_stopping_rounds=1000)\n",
    "    return model\n",
    "\n",
    "def train_xgb(X_val,y_val,X_train,y_train,xgb_params):\n",
    "    \n",
    "    model = xgb.XGBRegressor(params=xgb_params)\n",
    "    model.fit(X_train,y_train,\n",
    "              eval_set=[(X_val,y_val),(X_train,y_train)], \n",
    "              verbose=5000,eval_metric='mae',\n",
    "              early_stopping_rounds=1000)\n",
    "    \n",
    "    best_iteration = model.get_booster().best_ntree_limit\n",
    "    return model\n",
    "\n",
    "def seq_model(train_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8,input_shape = (train_shape,),activation = 'relu'))\n",
    "\n",
    "    model.add(Dropout(0.3))\n",
    "#     model.add(Dense(16,activation = 'relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    model.compile(loss = 'mae',optimizer = 'adam')\n",
    "    return model\n",
    "\n",
    "def train_nn(X_val,y_val,X_train,y_train):\n",
    "    \n",
    "    model = seq_model(X_train.shape[1])\n",
    "    mcp_save = ModelCheckpoint('.mdl_wtsPL.hdf5', \n",
    "                               save_best_only=True,\n",
    "                               monitor='val_loss',\n",
    "                               mode='min',verbose=1)\n",
    "    model.fit(X_train,y_train,\n",
    "              validation_data=(X_val,y_val), \n",
    "              verbose=-1,epochs=50,callbacks=[mcp_save])\n",
    "    model.load_weights(filepath = '.mdl_wtsPL.hdf5')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "folds = KFold(n_splits=3,shuffle=True,random_state=1)\n",
    "\n",
    "xgb_params = {'eta': 0.01,\n",
    "              'max_depth': 6,\n",
    "              'subsample': 0.8,\n",
    "              'colsample_bytree': 0.8,\n",
    "              'colsample_bylevel': 0.8,\n",
    "              'colsample_bynode': 0.8,\n",
    "              'lambda': 0.1,\n",
    "              'alpha' : 0.1,\n",
    "\n",
    "              'eval_metric': 'mae',\n",
    "              'silent': True,\n",
    "              'nthread': 4\n",
    "             }\n",
    "lgb_params = {'num_leaves': 4,\n",
    "          'min_data_in_leaf': 5,\n",
    "          'objective':'fair',\n",
    "          'max_depth': -1,\n",
    "          'learning_rate': 0.02,\n",
    "          \"boosting\": \"gbdt\",\n",
    "          'boost_from_average': True,\n",
    "          \"feature_fraction\": 0.9,\n",
    "          \"bagging_freq\": 1,\n",
    "          \"bagging_fraction\": 0.5,\n",
    "          \"bagging_seed\": 0,\n",
    "          \"metric\": 'mae',\n",
    "          \"verbosity\": -1,\n",
    "          'max_bin': 500,\n",
    "          'reg_alpha': 0,\n",
    "          'reg_lambda': 0,\n",
    "          'seed': 0\n",
    "         }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_experiment [1, 2, 4, 7, 9, 10, 11, 12, 14]\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[313]\ttraining's l1: 1.6435\tvalid_0's l1: 1.78069\n",
      "[13:29:44] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation_0-mae:5.33605\tvalidation_1-mae:5.31015\n",
      "Multiple eval metrics have been passed: 'validation_1-mae' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-mae hasn't improved in 1000 rounds.\n",
      "[99]\tvalidation_0-mae:1.81516\tvalidation_1-mae:1.53938\n",
      "Train on 1884 samples, validate on 943 samples\n",
      "Epoch 1/50\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 6.19131, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 2/50\n",
      "\n",
      "Epoch 00002: val_loss improved from 6.19131 to 5.92769, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 3/50\n",
      "\n",
      "Epoch 00003: val_loss improved from 5.92769 to 5.49363, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 4/50\n",
      "\n",
      "Epoch 00004: val_loss improved from 5.49363 to 5.07200, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 5/50\n",
      "\n",
      "Epoch 00005: val_loss improved from 5.07200 to 4.44645, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 6/50\n",
      "\n",
      "Epoch 00006: val_loss improved from 4.44645 to 3.83282, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 7/50\n",
      "\n",
      "Epoch 00007: val_loss improved from 3.83282 to 3.17259, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 8/50\n",
      "\n",
      "Epoch 00008: val_loss improved from 3.17259 to 2.51118, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 9/50\n",
      "\n",
      "Epoch 00009: val_loss improved from 2.51118 to 2.22819, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 10/50\n",
      "\n",
      "Epoch 00010: val_loss improved from 2.22819 to 2.05957, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 11/50\n",
      "\n",
      "Epoch 00011: val_loss improved from 2.05957 to 1.99237, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 12/50\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.99237 to 1.91005, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 13/50\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.91005 to 1.88349, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 14/50\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.88349 to 1.88229, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 15/50\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.88229\n",
      "Epoch 16/50\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.88229\n",
      "Epoch 17/50\n",
      "\n",
      "Epoch 00017: val_loss improved from 1.88229 to 1.86562, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 18/50\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.86562\n",
      "Epoch 19/50\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.86562\n",
      "Epoch 20/50\n",
      "\n",
      "Epoch 00020: val_loss improved from 1.86562 to 1.86062, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 21/50\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.86062\n",
      "Epoch 22/50\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1.86062\n",
      "Epoch 23/50\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1.86062\n",
      "Epoch 24/50\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1.86062\n",
      "Epoch 25/50\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1.86062\n",
      "Epoch 26/50\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1.86062\n",
      "Epoch 27/50\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1.86062\n",
      "Epoch 28/50\n",
      "\n",
      "Epoch 00028: val_loss improved from 1.86062 to 1.85395, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 29/50\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1.85395\n",
      "Epoch 30/50\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1.85395\n",
      "Epoch 31/50\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 1.85395\n",
      "Epoch 32/50\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1.85395\n",
      "Epoch 33/50\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1.85395\n",
      "Epoch 34/50\n",
      "\n",
      "Epoch 00034: val_loss improved from 1.85395 to 1.85333, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 35/50\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 1.85333\n",
      "Epoch 36/50\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 1.85333\n",
      "Epoch 37/50\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 1.85333\n",
      "Epoch 38/50\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1.85333\n",
      "Epoch 39/50\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 1.85333\n",
      "Epoch 40/50\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1.85333\n",
      "Epoch 41/50\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 1.85333\n",
      "Epoch 42/50\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1.85333\n",
      "Epoch 43/50\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 1.85333\n",
      "Epoch 44/50\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 1.85333\n",
      "Epoch 45/50\n",
      "\n",
      "Epoch 00045: val_loss improved from 1.85333 to 1.84819, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 46/50\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 1.84819\n",
      "Epoch 47/50\n",
      "\n",
      "Epoch 00047: val_loss improved from 1.84819 to 1.84752, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 48/50\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 1.84752\n",
      "Epoch 49/50\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 1.84752\n",
      "Epoch 50/50\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 1.84752\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[249]\ttraining's l1: 1.60367\tvalid_0's l1: 1.90497\n",
      "[13:30:18] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation_0-mae:5.3634\tvalidation_1-mae:5.29651\n",
      "Multiple eval metrics have been passed: 'validation_1-mae' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-mae hasn't improved in 1000 rounds.\n",
      "[99]\tvalidation_0-mae:1.98018\tvalidation_1-mae:1.43979\n",
      "Train on 1885 samples, validate on 942 samples\n",
      "Epoch 1/50\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 6.23420, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 2/50\n",
      "\n",
      "Epoch 00002: val_loss improved from 6.23420 to 5.95545, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 3/50\n",
      "\n",
      "Epoch 00003: val_loss improved from 5.95545 to 5.61525, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 4/50\n",
      "\n",
      "Epoch 00004: val_loss improved from 5.61525 to 5.13799, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 5/50\n",
      "\n",
      "Epoch 00005: val_loss improved from 5.13799 to 4.56383, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 6/50\n",
      "\n",
      "Epoch 00006: val_loss improved from 4.56383 to 3.95609, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 7/50\n",
      "\n",
      "Epoch 00007: val_loss improved from 3.95609 to 3.24859, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 8/50\n",
      "\n",
      "Epoch 00008: val_loss improved from 3.24859 to 2.69996, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 9/50\n",
      "\n",
      "Epoch 00009: val_loss improved from 2.69996 to 2.37493, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 10/50\n",
      "\n",
      "Epoch 00010: val_loss improved from 2.37493 to 2.20921, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 11/50\n",
      "\n",
      "Epoch 00011: val_loss improved from 2.20921 to 2.15958, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 12/50\n",
      "\n",
      "Epoch 00012: val_loss improved from 2.15958 to 2.14212, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 13/50\n",
      "\n",
      "Epoch 00013: val_loss improved from 2.14212 to 2.13012, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 14/50\n",
      "\n",
      "Epoch 00014: val_loss improved from 2.13012 to 2.11252, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 15/50\n",
      "\n",
      "Epoch 00015: val_loss improved from 2.11252 to 2.10890, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 16/50\n",
      "\n",
      "Epoch 00016: val_loss improved from 2.10890 to 2.10679, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 17/50\n",
      "\n",
      "Epoch 00017: val_loss improved from 2.10679 to 2.10594, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 18/50\n",
      "\n",
      "Epoch 00018: val_loss improved from 2.10594 to 2.10447, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 19/50\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 2.10447\n",
      "Epoch 20/50\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 2.10447\n",
      "Epoch 21/50\n",
      "\n",
      "Epoch 00021: val_loss improved from 2.10447 to 2.09132, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 22/50\n",
      "\n",
      "Epoch 00022: val_loss improved from 2.09132 to 2.08532, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 23/50\n",
      "\n",
      "Epoch 00023: val_loss improved from 2.08532 to 2.07807, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 24/50\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 2.07807\n",
      "Epoch 25/50\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 2.07807\n",
      "Epoch 26/50\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 2.07807\n",
      "Epoch 27/50\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 2.07807\n",
      "Epoch 28/50\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 2.07807\n",
      "Epoch 29/50\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 2.07807\n",
      "Epoch 30/50\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 2.07807\n",
      "Epoch 31/50\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 2.07807\n",
      "Epoch 32/50\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 2.07807\n",
      "Epoch 33/50\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 2.07807\n",
      "Epoch 34/50\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 2.07807\n",
      "Epoch 35/50\n",
      "\n",
      "Epoch 00035: val_loss improved from 2.07807 to 2.07697, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 36/50\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 2.07697\n",
      "Epoch 37/50\n",
      "\n",
      "Epoch 00037: val_loss improved from 2.07697 to 2.07362, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 38/50\n",
      "\n",
      "Epoch 00038: val_loss improved from 2.07362 to 2.07345, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 39/50\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 2.07345\n",
      "Epoch 40/50\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 2.07345\n",
      "Epoch 41/50\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 2.07345\n",
      "Epoch 42/50\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 2.07345\n",
      "Epoch 43/50\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 2.07345\n",
      "Epoch 44/50\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 2.07345\n",
      "Epoch 45/50\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 2.07345\n",
      "Epoch 46/50\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 2.07345\n",
      "Epoch 47/50\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 2.07345\n",
      "Epoch 48/50\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 2.07345\n",
      "Epoch 49/50\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 2.07345\n",
      "Epoch 50/50\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 2.07345\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[150]\ttraining's l1: 1.69913\tvalid_0's l1: 1.86435\n",
      "[13:30:48] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation_0-mae:5.25507\tvalidation_1-mae:5.34179\n",
      "Multiple eval metrics have been passed: 'validation_1-mae' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-mae hasn't improved in 1000 rounds.\n",
      "[99]\tvalidation_0-mae:1.88131\tvalidation_1-mae:1.47004\n",
      "Train on 1885 samples, validate on 942 samples\n",
      "Epoch 1/50\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 6.00402, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 2/50\n",
      "\n",
      "Epoch 00002: val_loss improved from 6.00402 to 5.75123, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 3/50\n",
      "\n",
      "Epoch 00003: val_loss improved from 5.75123 to 5.38208, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 4/50\n",
      "\n",
      "Epoch 00004: val_loss improved from 5.38208 to 5.00502, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 5/50\n",
      "\n",
      "Epoch 00005: val_loss improved from 5.00502 to 4.41523, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 6/50\n",
      "\n",
      "Epoch 00006: val_loss improved from 4.41523 to 3.73940, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 7/50\n",
      "\n",
      "Epoch 00007: val_loss improved from 3.73940 to 3.08295, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 8/50\n",
      "\n",
      "Epoch 00008: val_loss improved from 3.08295 to 2.53496, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 9/50\n",
      "\n",
      "Epoch 00009: val_loss improved from 2.53496 to 2.20626, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 10/50\n",
      "\n",
      "Epoch 00010: val_loss improved from 2.20626 to 2.06809, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 11/50\n",
      "\n",
      "Epoch 00011: val_loss improved from 2.06809 to 2.00747, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 12/50\n",
      "\n",
      "Epoch 00012: val_loss improved from 2.00747 to 1.98644, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 13/50\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.98644 to 1.97841, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 14/50\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.97841 to 1.97788, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 15/50\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.97788\n",
      "Epoch 16/50\n",
      "\n",
      "Epoch 00016: val_loss improved from 1.97788 to 1.97598, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 17/50\n",
      "\n",
      "Epoch 00017: val_loss improved from 1.97598 to 1.97557, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 18/50\n",
      "\n",
      "Epoch 00018: val_loss improved from 1.97557 to 1.95580, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 19/50\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.95580\n",
      "Epoch 20/50\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.95580\n",
      "Epoch 21/50\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.95580\n",
      "Epoch 22/50\n",
      "\n",
      "Epoch 00022: val_loss improved from 1.95580 to 1.94705, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 23/50\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1.94705\n",
      "Epoch 24/50\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1.94705\n",
      "Epoch 25/50\n",
      "\n",
      "Epoch 00025: val_loss improved from 1.94705 to 1.94546, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 26/50\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1.94546\n",
      "Epoch 27/50\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1.94546\n",
      "Epoch 28/50\n",
      "\n",
      "Epoch 00028: val_loss improved from 1.94546 to 1.93942, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 29/50\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1.93942\n",
      "Epoch 30/50\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1.93942\n",
      "Epoch 31/50\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 1.93942\n",
      "Epoch 32/50\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1.93942\n",
      "Epoch 33/50\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1.93942\n",
      "Epoch 34/50\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1.93942\n",
      "Epoch 35/50\n",
      "\n",
      "Epoch 00035: val_loss improved from 1.93942 to 1.93582, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 36/50\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 1.93582\n",
      "Epoch 37/50\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 1.93582\n",
      "Epoch 38/50\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1.93582\n",
      "Epoch 39/50\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 1.93582\n",
      "Epoch 40/50\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1.93582\n",
      "Epoch 41/50\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 1.93582\n",
      "Epoch 42/50\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1.93582\n",
      "Epoch 43/50\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 1.93582\n",
      "Epoch 44/50\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 1.93582\n",
      "Epoch 45/50\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 1.93582\n",
      "Epoch 46/50\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 1.93582\n",
      "Epoch 47/50\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 1.93582\n",
      "Epoch 48/50\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 1.93582\n",
      "Epoch 49/50\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 1.93582\n",
      "Epoch 50/50\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 1.93582\n",
      "train_experiment [1, 2, 4, 7, 8, 9, 10, 11, 14]\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[183]\ttraining's l1: 1.76416\tvalid_0's l1: 1.98185\n",
      "[13:31:23] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation_0-mae:5.21078\tvalidation_1-mae:5.34654\n",
      "Multiple eval metrics have been passed: 'validation_1-mae' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-mae hasn't improved in 1000 rounds.\n",
      "[99]\tvalidation_0-mae:2.00998\tvalidation_1-mae:1.54366\n",
      "Train on 1868 samples, validate on 935 samples\n",
      "Epoch 1/50\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 6.03933, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 2/50\n",
      "\n",
      "Epoch 00002: val_loss improved from 6.03933 to 5.84177, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 3/50\n",
      "\n",
      "Epoch 00003: val_loss improved from 5.84177 to 5.48961, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 4/50\n",
      "\n",
      "Epoch 00004: val_loss improved from 5.48961 to 5.10997, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 5/50\n",
      "\n",
      "Epoch 00005: val_loss improved from 5.10997 to 4.46816, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 6/50\n",
      "\n",
      "Epoch 00006: val_loss improved from 4.46816 to 3.79182, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 7/50\n",
      "\n",
      "Epoch 00007: val_loss improved from 3.79182 to 3.18005, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 8/50\n",
      "\n",
      "Epoch 00008: val_loss improved from 3.18005 to 2.76312, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 9/50\n",
      "\n",
      "Epoch 00009: val_loss improved from 2.76312 to 2.33844, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 10/50\n",
      "\n",
      "Epoch 00010: val_loss improved from 2.33844 to 2.16987, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 11/50\n",
      "\n",
      "Epoch 00011: val_loss improved from 2.16987 to 2.09432, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 12/50\n",
      "\n",
      "Epoch 00012: val_loss improved from 2.09432 to 2.08320, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 13/50\n",
      "\n",
      "Epoch 00013: val_loss improved from 2.08320 to 2.05999, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 14/50\n",
      "\n",
      "Epoch 00014: val_loss improved from 2.05999 to 2.05866, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 15/50\n",
      "\n",
      "Epoch 00015: val_loss improved from 2.05866 to 2.05627, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 16/50\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 2.05627\n",
      "Epoch 17/50\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 2.05627\n",
      "Epoch 18/50\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 2.05627\n",
      "Epoch 19/50\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 2.05627\n",
      "Epoch 20/50\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 2.05627\n",
      "Epoch 21/50\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 2.05627\n",
      "Epoch 22/50\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 2.05627\n",
      "Epoch 23/50\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 2.05627\n",
      "Epoch 24/50\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 2.05627\n",
      "Epoch 25/50\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 2.05627\n",
      "Epoch 26/50\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 2.05627\n",
      "Epoch 27/50\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 2.05627\n",
      "Epoch 28/50\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 2.05627\n",
      "Epoch 29/50\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 2.05627\n",
      "Epoch 30/50\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 2.05627\n",
      "Epoch 31/50\n",
      "\n",
      "Epoch 00031: val_loss improved from 2.05627 to 2.05152, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 32/50\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 2.05152\n",
      "Epoch 33/50\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 2.05152\n",
      "Epoch 34/50\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 2.05152\n",
      "Epoch 35/50\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 2.05152\n",
      "Epoch 36/50\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 2.05152\n",
      "Epoch 37/50\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 2.05152\n",
      "Epoch 38/50\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 2.05152\n",
      "Epoch 39/50\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 2.05152\n",
      "Epoch 40/50\n",
      "\n",
      "Epoch 00040: val_loss improved from 2.05152 to 2.04717, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 41/50\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 2.04717\n",
      "Epoch 42/50\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 2.04717\n",
      "Epoch 43/50\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 2.04717\n",
      "Epoch 44/50\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 2.04717\n",
      "Epoch 45/50\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 2.04717\n",
      "Epoch 46/50\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 2.04717\n",
      "Epoch 47/50\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 2.04717\n",
      "Epoch 48/50\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 2.04717\n",
      "Epoch 49/50\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 2.04717\n",
      "Epoch 50/50\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 2.04717\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[336]\ttraining's l1: 1.66225\tvalid_0's l1: 1.96822\n",
      "[13:31:55] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation_0-mae:5.35035\tvalidation_1-mae:5.27881\n",
      "Multiple eval metrics have been passed: 'validation_1-mae' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-mae hasn't improved in 1000 rounds.\n",
      "[99]\tvalidation_0-mae:1.9732\tvalidation_1-mae:1.55997\n",
      "Train on 1869 samples, validate on 934 samples\n",
      "Epoch 1/50\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 6.22133, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 2/50\n",
      "\n",
      "Epoch 00002: val_loss improved from 6.22133 to 6.04003, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 3/50\n",
      "\n",
      "Epoch 00003: val_loss improved from 6.04003 to 5.65306, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 4/50\n",
      "\n",
      "Epoch 00004: val_loss improved from 5.65306 to 5.17198, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 5/50\n",
      "\n",
      "Epoch 00005: val_loss improved from 5.17198 to 4.45514, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 6/50\n",
      "\n",
      "Epoch 00006: val_loss improved from 4.45514 to 3.85418, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 7/50\n",
      "\n",
      "Epoch 00007: val_loss improved from 3.85418 to 3.26856, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 8/50\n",
      "\n",
      "Epoch 00008: val_loss improved from 3.26856 to 2.79795, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 9/50\n",
      "\n",
      "Epoch 00009: val_loss improved from 2.79795 to 2.44248, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 10/50\n",
      "\n",
      "Epoch 00010: val_loss improved from 2.44248 to 2.27120, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 11/50\n",
      "\n",
      "Epoch 00011: val_loss improved from 2.27120 to 2.17161, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 12/50\n",
      "\n",
      "Epoch 00012: val_loss improved from 2.17161 to 2.12074, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 13/50\n",
      "\n",
      "Epoch 00013: val_loss improved from 2.12074 to 2.10107, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 14/50\n",
      "\n",
      "Epoch 00014: val_loss improved from 2.10107 to 2.09551, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 15/50\n",
      "\n",
      "Epoch 00015: val_loss improved from 2.09551 to 2.08786, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 16/50\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 2.08786\n",
      "Epoch 17/50\n",
      "\n",
      "Epoch 00017: val_loss improved from 2.08786 to 2.08565, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 18/50\n",
      "\n",
      "Epoch 00018: val_loss improved from 2.08565 to 2.08418, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 19/50\n",
      "\n",
      "Epoch 00019: val_loss improved from 2.08418 to 2.08108, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 20/50\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 2.08108\n",
      "Epoch 21/50\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 2.08108\n",
      "Epoch 22/50\n",
      "\n",
      "Epoch 00022: val_loss improved from 2.08108 to 2.08019, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 23/50\n",
      "\n",
      "Epoch 00023: val_loss improved from 2.08019 to 2.07837, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 24/50\n",
      "\n",
      "Epoch 00024: val_loss improved from 2.07837 to 2.07246, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 25/50\n",
      "\n",
      "Epoch 00025: val_loss improved from 2.07246 to 2.06832, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 26/50\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 2.06832\n",
      "Epoch 27/50\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 2.06832\n",
      "Epoch 28/50\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 2.06832\n",
      "Epoch 29/50\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 2.06832\n",
      "Epoch 30/50\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 2.06832\n",
      "Epoch 31/50\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 2.06832\n",
      "Epoch 32/50\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 2.06832\n",
      "Epoch 33/50\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 2.06832\n",
      "Epoch 34/50\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 2.06832\n",
      "Epoch 35/50\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 2.06832\n",
      "Epoch 36/50\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 2.06832\n",
      "Epoch 37/50\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 2.06832\n",
      "Epoch 38/50\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 2.06832\n",
      "Epoch 39/50\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 2.06832\n",
      "Epoch 40/50\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 2.06832\n",
      "Epoch 41/50\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 2.06832\n",
      "Epoch 42/50\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 2.06832\n",
      "Epoch 43/50\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 2.06832\n",
      "Epoch 44/50\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 2.06832\n",
      "Epoch 45/50\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 2.06832\n",
      "Epoch 46/50\n",
      "\n",
      "Epoch 00046: val_loss improved from 2.06832 to 2.06344, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 47/50\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 2.06344\n",
      "Epoch 48/50\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 2.06344\n",
      "Epoch 49/50\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 2.06344\n",
      "Epoch 50/50\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 2.06344\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[217]\ttraining's l1: 1.74834\tvalid_0's l1: 1.9601\n",
      "[13:32:29] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation_0-mae:5.34941\tvalidation_1-mae:5.27955\n",
      "Multiple eval metrics have been passed: 'validation_1-mae' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-mae hasn't improved in 1000 rounds.\n",
      "[99]\tvalidation_0-mae:2.01713\tvalidation_1-mae:1.55395\n",
      "Train on 1869 samples, validate on 934 samples\n",
      "Epoch 1/50\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 6.28446, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 2/50\n",
      "\n",
      "Epoch 00002: val_loss improved from 6.28446 to 5.84499, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 3/50\n",
      "\n",
      "Epoch 00003: val_loss improved from 5.84499 to 5.34893, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 4/50\n",
      "\n",
      "Epoch 00004: val_loss improved from 5.34893 to 4.80005, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 5/50\n",
      "\n",
      "Epoch 00005: val_loss improved from 4.80005 to 4.21582, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 6/50\n",
      "\n",
      "Epoch 00006: val_loss improved from 4.21582 to 3.48736, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 7/50\n",
      "\n",
      "Epoch 00007: val_loss improved from 3.48736 to 3.01300, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 8/50\n",
      "\n",
      "Epoch 00008: val_loss improved from 3.01300 to 2.64366, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 9/50\n",
      "\n",
      "Epoch 00009: val_loss improved from 2.64366 to 2.42906, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 10/50\n",
      "\n",
      "Epoch 00010: val_loss improved from 2.42906 to 2.27826, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 11/50\n",
      "\n",
      "Epoch 00011: val_loss improved from 2.27826 to 2.16088, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 12/50\n",
      "\n",
      "Epoch 00012: val_loss improved from 2.16088 to 2.13668, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 13/50\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 2.13668\n",
      "Epoch 14/50\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 2.13668\n",
      "Epoch 15/50\n",
      "\n",
      "Epoch 00015: val_loss improved from 2.13668 to 2.13060, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 16/50\n",
      "\n",
      "Epoch 00016: val_loss improved from 2.13060 to 2.11752, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 17/50\n",
      "\n",
      "Epoch 00017: val_loss improved from 2.11752 to 2.11277, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 18/50\n",
      "\n",
      "Epoch 00018: val_loss improved from 2.11277 to 2.08816, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 19/50\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 2.08816\n",
      "Epoch 20/50\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 2.08816\n",
      "Epoch 21/50\n",
      "\n",
      "Epoch 00021: val_loss improved from 2.08816 to 2.08375, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 22/50\n",
      "\n",
      "Epoch 00022: val_loss improved from 2.08375 to 2.08289, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 23/50\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 2.08289\n",
      "Epoch 24/50\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 2.08289\n",
      "Epoch 25/50\n",
      "\n",
      "Epoch 00025: val_loss improved from 2.08289 to 2.08025, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 26/50\n",
      "\n",
      "Epoch 00026: val_loss improved from 2.08025 to 2.05021, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 27/50\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 2.05021\n",
      "Epoch 28/50\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 2.05021\n",
      "Epoch 29/50\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 2.05021\n",
      "Epoch 30/50\n",
      "\n",
      "Epoch 00030: val_loss improved from 2.05021 to 2.04685, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 31/50\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 2.04685\n",
      "Epoch 32/50\n",
      "\n",
      "Epoch 00032: val_loss improved from 2.04685 to 2.04465, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 33/50\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 2.04465\n",
      "Epoch 34/50\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 2.04465\n",
      "Epoch 35/50\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 2.04465\n",
      "Epoch 36/50\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 2.04465\n",
      "Epoch 37/50\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 2.04465\n",
      "Epoch 38/50\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 2.04465\n",
      "Epoch 39/50\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 2.04465\n",
      "Epoch 40/50\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 2.04465\n",
      "Epoch 41/50\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 2.04465\n",
      "Epoch 42/50\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 2.04465\n",
      "Epoch 43/50\n",
      "\n",
      "Epoch 00043: val_loss improved from 2.04465 to 2.02999, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 44/50\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 2.02999\n",
      "Epoch 45/50\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 2.02999\n",
      "Epoch 46/50\n",
      "\n",
      "Epoch 00046: val_loss improved from 2.02999 to 2.02680, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 47/50\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 2.02680\n",
      "Epoch 48/50\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 2.02680\n",
      "Epoch 49/50\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 2.02680\n",
      "Epoch 50/50\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 2.02680\n",
      "train_experiment [1, 2, 4, 7, 10, 11, 14]\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[278]\ttraining's l1: 1.44511\tvalid_0's l1: 1.86273\n",
      "[13:33:01] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation_0-mae:5.71615\tvalidation_1-mae:5.57918\n",
      "Multiple eval metrics have been passed: 'validation_1-mae' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-mae hasn't improved in 1000 rounds.\n",
      "[99]\tvalidation_0-mae:1.95673\tvalidation_1-mae:1.2887\n",
      "Train on 1568 samples, validate on 785 samples\n",
      "Epoch 1/50\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 6.59260, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 2/50\n",
      "\n",
      "Epoch 00002: val_loss improved from 6.59260 to 6.33572, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 3/50\n",
      "\n",
      "Epoch 00003: val_loss improved from 6.33572 to 6.09143, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 4/50\n",
      "\n",
      "Epoch 00004: val_loss improved from 6.09143 to 5.77886, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 5/50\n",
      "\n",
      "Epoch 00005: val_loss improved from 5.77886 to 5.29146, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 6/50\n",
      "\n",
      "Epoch 00006: val_loss improved from 5.29146 to 4.82460, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 7/50\n",
      "\n",
      "Epoch 00007: val_loss improved from 4.82460 to 4.15636, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 8/50\n",
      "\n",
      "Epoch 00008: val_loss improved from 4.15636 to 3.57426, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 9/50\n",
      "\n",
      "Epoch 00009: val_loss improved from 3.57426 to 3.03856, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 10/50\n",
      "\n",
      "Epoch 00010: val_loss improved from 3.03856 to 2.71273, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 11/50\n",
      "\n",
      "Epoch 00011: val_loss improved from 2.71273 to 2.34346, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 12/50\n",
      "\n",
      "Epoch 00012: val_loss improved from 2.34346 to 2.11536, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 13/50\n",
      "\n",
      "Epoch 00013: val_loss improved from 2.11536 to 2.04606, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 14/50\n",
      "\n",
      "Epoch 00014: val_loss improved from 2.04606 to 2.01538, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 15/50\n",
      "\n",
      "Epoch 00015: val_loss improved from 2.01538 to 1.98684, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 16/50\n",
      "\n",
      "Epoch 00016: val_loss improved from 1.98684 to 1.98566, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 17/50\n",
      "\n",
      "Epoch 00017: val_loss improved from 1.98566 to 1.98164, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 18/50\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.98164\n",
      "Epoch 19/50\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.98164\n",
      "Epoch 20/50\n",
      "\n",
      "Epoch 00020: val_loss improved from 1.98164 to 1.97996, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 21/50\n",
      "\n",
      "Epoch 00021: val_loss improved from 1.97996 to 1.97333, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 22/50\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1.97333\n",
      "Epoch 23/50\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1.97333\n",
      "Epoch 24/50\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1.97333\n",
      "Epoch 25/50\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1.97333\n",
      "Epoch 26/50\n",
      "\n",
      "Epoch 00026: val_loss improved from 1.97333 to 1.96660, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 27/50\n",
      "\n",
      "Epoch 00027: val_loss improved from 1.96660 to 1.96259, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 28/50\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1.96259\n",
      "Epoch 29/50\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1.96259\n",
      "Epoch 30/50\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1.96259\n",
      "Epoch 31/50\n",
      "\n",
      "Epoch 00031: val_loss improved from 1.96259 to 1.96082, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 32/50\n",
      "\n",
      "Epoch 00032: val_loss improved from 1.96082 to 1.95935, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 33/50\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1.95935\n",
      "Epoch 34/50\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1.95935\n",
      "Epoch 35/50\n",
      "\n",
      "Epoch 00035: val_loss improved from 1.95935 to 1.95520, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 36/50\n",
      "\n",
      "Epoch 00036: val_loss improved from 1.95520 to 1.95007, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 37/50\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 1.95007\n",
      "Epoch 38/50\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1.95007\n",
      "Epoch 39/50\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 1.95007\n",
      "Epoch 40/50\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1.95007\n",
      "Epoch 41/50\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 1.95007\n",
      "Epoch 42/50\n",
      "\n",
      "Epoch 00042: val_loss improved from 1.95007 to 1.94943, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 43/50\n",
      "\n",
      "Epoch 00043: val_loss improved from 1.94943 to 1.94738, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 44/50\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 1.94738\n",
      "Epoch 45/50\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 1.94738\n",
      "Epoch 46/50\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 1.94738\n",
      "Epoch 47/50\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 1.94738\n",
      "Epoch 48/50\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 1.94738\n",
      "Epoch 49/50\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 1.94738\n",
      "Epoch 50/50\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 1.94738\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[308]\ttraining's l1: 1.49847\tvalid_0's l1: 1.67516\n",
      "[13:33:32] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation_0-mae:5.63128\tvalidation_1-mae:5.62275\n",
      "Multiple eval metrics have been passed: 'validation_1-mae' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-mae hasn't improved in 1000 rounds.\n",
      "[99]\tvalidation_0-mae:1.73338\tvalidation_1-mae:1.37765\n",
      "Train on 1569 samples, validate on 784 samples\n",
      "Epoch 1/50\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 6.54625, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 2/50\n",
      "\n",
      "Epoch 00002: val_loss improved from 6.54625 to 6.33495, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 3/50\n",
      "\n",
      "Epoch 00003: val_loss improved from 6.33495 to 6.11554, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 4/50\n",
      "\n",
      "Epoch 00004: val_loss improved from 6.11554 to 5.67893, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 5/50\n",
      "\n",
      "Epoch 00005: val_loss improved from 5.67893 to 5.20748, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 6/50\n",
      "\n",
      "Epoch 00006: val_loss improved from 5.20748 to 4.62834, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 7/50\n",
      "\n",
      "Epoch 00007: val_loss improved from 4.62834 to 4.11094, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 8/50\n",
      "\n",
      "Epoch 00008: val_loss improved from 4.11094 to 3.56062, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 9/50\n",
      "\n",
      "Epoch 00009: val_loss improved from 3.56062 to 2.75420, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 10/50\n",
      "\n",
      "Epoch 00010: val_loss improved from 2.75420 to 2.30322, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 11/50\n",
      "\n",
      "Epoch 00011: val_loss improved from 2.30322 to 2.08010, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 12/50\n",
      "\n",
      "Epoch 00012: val_loss improved from 2.08010 to 1.99367, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 13/50\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.99367 to 1.95683, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 14/50\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.95683 to 1.90036, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 15/50\n",
      "\n",
      "Epoch 00015: val_loss improved from 1.90036 to 1.89240, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 16/50\n",
      "\n",
      "Epoch 00016: val_loss improved from 1.89240 to 1.88917, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 17/50\n",
      "\n",
      "Epoch 00017: val_loss improved from 1.88917 to 1.86985, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 18/50\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.86985\n",
      "Epoch 19/50\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.86985\n",
      "Epoch 20/50\n",
      "\n",
      "Epoch 00020: val_loss improved from 1.86985 to 1.86971, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 21/50\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.86971\n",
      "Epoch 22/50\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1.86971\n",
      "Epoch 23/50\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1.86971\n",
      "Epoch 24/50\n",
      "\n",
      "Epoch 00024: val_loss improved from 1.86971 to 1.86585, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 25/50\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1.86585\n",
      "Epoch 26/50\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1.86585\n",
      "Epoch 27/50\n",
      "\n",
      "Epoch 00027: val_loss improved from 1.86585 to 1.84604, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 28/50\n",
      "\n",
      "Epoch 00028: val_loss improved from 1.84604 to 1.84503, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 29/50\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1.84503\n",
      "Epoch 30/50\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1.84503\n",
      "Epoch 31/50\n",
      "\n",
      "Epoch 00031: val_loss improved from 1.84503 to 1.83713, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 32/50\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1.83713\n",
      "Epoch 33/50\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1.83713\n",
      "Epoch 34/50\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1.83713\n",
      "Epoch 35/50\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 1.83713\n",
      "Epoch 36/50\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 1.83713\n",
      "Epoch 37/50\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 1.83713\n",
      "Epoch 38/50\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1.83713\n",
      "Epoch 39/50\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 1.83713\n",
      "Epoch 40/50\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1.83713\n",
      "Epoch 41/50\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 1.83713\n",
      "Epoch 42/50\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1.83713\n",
      "Epoch 43/50\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 1.83713\n",
      "Epoch 44/50\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 1.83713\n",
      "Epoch 45/50\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 1.83713\n",
      "Epoch 46/50\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 1.83713\n",
      "Epoch 47/50\n",
      "\n",
      "Epoch 00047: val_loss improved from 1.83713 to 1.82939, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 48/50\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 1.82939\n",
      "Epoch 49/50\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 1.82939\n",
      "Epoch 50/50\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 1.82939\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[133]\ttraining's l1: 1.63435\tvalid_0's l1: 1.69653\n",
      "[13:34:03] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation_0-mae:5.53033\tvalidation_1-mae:5.66738\n",
      "Multiple eval metrics have been passed: 'validation_1-mae' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-mae hasn't improved in 1000 rounds.\n",
      "[99]\tvalidation_0-mae:1.78607\tvalidation_1-mae:1.37155\n",
      "Train on 1569 samples, validate on 784 samples\n",
      "Epoch 1/50\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 6.54769, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 2/50\n",
      "\n",
      "Epoch 00002: val_loss improved from 6.54769 to 6.31513, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 3/50\n",
      "\n",
      "Epoch 00003: val_loss improved from 6.31513 to 6.05000, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 4/50\n",
      "\n",
      "Epoch 00004: val_loss improved from 6.05000 to 5.66283, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 5/50\n",
      "\n",
      "Epoch 00005: val_loss improved from 5.66283 to 5.16086, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 6/50\n",
      "\n",
      "Epoch 00006: val_loss improved from 5.16086 to 4.66040, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 7/50\n",
      "\n",
      "Epoch 00007: val_loss improved from 4.66040 to 3.97499, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 8/50\n",
      "\n",
      "Epoch 00008: val_loss improved from 3.97499 to 3.28036, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 9/50\n",
      "\n",
      "Epoch 00009: val_loss improved from 3.28036 to 2.73642, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 10/50\n",
      "\n",
      "Epoch 00010: val_loss improved from 2.73642 to 2.34758, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 11/50\n",
      "\n",
      "Epoch 00011: val_loss improved from 2.34758 to 2.07186, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 12/50\n",
      "\n",
      "Epoch 00012: val_loss improved from 2.07186 to 1.94723, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 13/50\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.94723 to 1.88668, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 14/50\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.88668 to 1.85905, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 15/50\n",
      "\n",
      "Epoch 00015: val_loss improved from 1.85905 to 1.83326, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 16/50\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.83326\n",
      "Epoch 17/50\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.83326\n",
      "Epoch 18/50\n",
      "\n",
      "Epoch 00018: val_loss improved from 1.83326 to 1.82348, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 19/50\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.82348\n",
      "Epoch 20/50\n",
      "\n",
      "Epoch 00020: val_loss improved from 1.82348 to 1.80998, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 21/50\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.80998\n",
      "Epoch 22/50\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1.80998\n",
      "Epoch 23/50\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1.80998\n",
      "Epoch 24/50\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1.80998\n",
      "Epoch 25/50\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1.80998\n",
      "Epoch 26/50\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1.80998\n",
      "Epoch 27/50\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1.80998\n",
      "Epoch 28/50\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1.80998\n",
      "Epoch 29/50\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1.80998\n",
      "Epoch 30/50\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1.80998\n",
      "Epoch 31/50\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 1.80998\n",
      "Epoch 32/50\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1.80998\n",
      "Epoch 33/50\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1.80998\n",
      "Epoch 34/50\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1.80998\n",
      "Epoch 35/50\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 1.80998\n",
      "Epoch 36/50\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 1.80998\n",
      "Epoch 37/50\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 1.80998\n",
      "Epoch 38/50\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1.80998\n",
      "Epoch 39/50\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 1.80998\n",
      "Epoch 40/50\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1.80998\n",
      "Epoch 41/50\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 1.80998\n",
      "Epoch 42/50\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1.80998\n",
      "Epoch 43/50\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 1.80998\n",
      "Epoch 44/50\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 1.80998\n",
      "Epoch 45/50\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 1.80998\n",
      "Epoch 46/50\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 1.80998\n",
      "Epoch 47/50\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 1.80998\n",
      "Epoch 48/50\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 1.80998\n",
      "Epoch 49/50\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 1.80998\n",
      "Epoch 50/50\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 1.80998\n",
      "train_experiment [1, 3, 7, 10, 11, 14]\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[228]\ttraining's l1: 1.5621\tvalid_0's l1: 1.83218\n",
      "[13:34:36] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation_0-mae:5.52447\tvalidation_1-mae:5.28899\n",
      "Multiple eval metrics have been passed: 'validation_1-mae' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-mae hasn't improved in 1000 rounds.\n",
      "[99]\tvalidation_0-mae:1.92252\tvalidation_1-mae:1.29472\n",
      "Train on 1261 samples, validate on 631 samples\n",
      "Epoch 1/50\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 6.50194, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 2/50\n",
      "\n",
      "Epoch 00002: val_loss improved from 6.50194 to 6.31888, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 3/50\n",
      "\n",
      "Epoch 00003: val_loss improved from 6.31888 to 6.13144, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 4/50\n",
      "\n",
      "Epoch 00004: val_loss improved from 6.13144 to 5.90833, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 5/50\n",
      "\n",
      "Epoch 00005: val_loss improved from 5.90833 to 5.54719, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 6/50\n",
      "\n",
      "Epoch 00006: val_loss improved from 5.54719 to 5.23106, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 7/50\n",
      "\n",
      "Epoch 00007: val_loss improved from 5.23106 to 4.84270, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 8/50\n",
      "\n",
      "Epoch 00008: val_loss improved from 4.84270 to 4.39773, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 9/50\n",
      "\n",
      "Epoch 00009: val_loss improved from 4.39773 to 3.84418, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 10/50\n",
      "\n",
      "Epoch 00010: val_loss improved from 3.84418 to 3.32827, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 11/50\n",
      "\n",
      "Epoch 00011: val_loss improved from 3.32827 to 2.89779, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 12/50\n",
      "\n",
      "Epoch 00012: val_loss improved from 2.89779 to 2.55460, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 13/50\n",
      "\n",
      "Epoch 00013: val_loss improved from 2.55460 to 2.28673, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 14/50\n",
      "\n",
      "Epoch 00014: val_loss improved from 2.28673 to 2.12983, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 15/50\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 2.12983\n",
      "Epoch 16/50\n",
      "\n",
      "Epoch 00016: val_loss improved from 2.12983 to 2.06595, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 17/50\n",
      "\n",
      "Epoch 00017: val_loss improved from 2.06595 to 1.98261, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 18/50\n",
      "\n",
      "Epoch 00018: val_loss improved from 1.98261 to 1.97810, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 19/50\n",
      "\n",
      "Epoch 00019: val_loss improved from 1.97810 to 1.95543, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 20/50\n",
      "\n",
      "Epoch 00020: val_loss improved from 1.95543 to 1.92998, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 21/50\n",
      "\n",
      "Epoch 00021: val_loss improved from 1.92998 to 1.92700, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 22/50\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1.92700\n",
      "Epoch 23/50\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1.92700\n",
      "Epoch 24/50\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1.92700\n",
      "Epoch 25/50\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1.92700\n",
      "Epoch 26/50\n",
      "\n",
      "Epoch 00026: val_loss improved from 1.92700 to 1.92207, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 27/50\n",
      "\n",
      "Epoch 00027: val_loss improved from 1.92207 to 1.90801, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 28/50\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1.90801\n",
      "Epoch 29/50\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1.90801\n",
      "Epoch 30/50\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1.90801\n",
      "Epoch 31/50\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 1.90801\n",
      "Epoch 32/50\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1.90801\n",
      "Epoch 33/50\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1.90801\n",
      "Epoch 34/50\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1.90801\n",
      "Epoch 35/50\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 1.90801\n",
      "Epoch 36/50\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 1.90801\n",
      "Epoch 37/50\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 1.90801\n",
      "Epoch 38/50\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1.90801\n",
      "Epoch 39/50\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 1.90801\n",
      "Epoch 40/50\n",
      "\n",
      "Epoch 00040: val_loss improved from 1.90801 to 1.89361, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 41/50\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 1.89361\n",
      "Epoch 42/50\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1.89361\n",
      "Epoch 43/50\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 1.89361\n",
      "Epoch 44/50\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 1.89361\n",
      "Epoch 45/50\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 1.89361\n",
      "Epoch 46/50\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 1.89361\n",
      "Epoch 47/50\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 1.89361\n",
      "Epoch 48/50\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 1.89361\n",
      "Epoch 49/50\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 1.89361\n",
      "Epoch 50/50\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 1.89361\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[154]\ttraining's l1: 1.63983\tvalid_0's l1: 1.77973\n",
      "[13:35:06] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation_0-mae:5.2961\tvalidation_1-mae:5.39203\n",
      "Multiple eval metrics have been passed: 'validation_1-mae' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-mae hasn't improved in 1000 rounds.\n",
      "[99]\tvalidation_0-mae:1.87232\tvalidation_1-mae:1.31461\n",
      "Train on 1261 samples, validate on 631 samples\n",
      "Epoch 1/50\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 6.20207, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 2/50\n",
      "\n",
      "Epoch 00002: val_loss improved from 6.20207 to 6.12652, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 3/50\n",
      "\n",
      "Epoch 00003: val_loss improved from 6.12652 to 5.92597, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 4/50\n",
      "\n",
      "Epoch 00004: val_loss improved from 5.92597 to 5.73974, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 5/50\n",
      "\n",
      "Epoch 00005: val_loss improved from 5.73974 to 5.42309, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 6/50\n",
      "\n",
      "Epoch 00006: val_loss improved from 5.42309 to 5.06838, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 7/50\n",
      "\n",
      "Epoch 00007: val_loss improved from 5.06838 to 4.65028, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 8/50\n",
      "\n",
      "Epoch 00008: val_loss improved from 4.65028 to 4.14996, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 9/50\n",
      "\n",
      "Epoch 00009: val_loss improved from 4.14996 to 3.66502, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 10/50\n",
      "\n",
      "Epoch 00010: val_loss improved from 3.66502 to 3.19962, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 11/50\n",
      "\n",
      "Epoch 00011: val_loss improved from 3.19962 to 2.87772, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 12/50\n",
      "\n",
      "Epoch 00012: val_loss improved from 2.87772 to 2.57754, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 13/50\n",
      "\n",
      "Epoch 00013: val_loss improved from 2.57754 to 2.33866, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 14/50\n",
      "\n",
      "Epoch 00014: val_loss improved from 2.33866 to 2.19875, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 15/50\n",
      "\n",
      "Epoch 00015: val_loss improved from 2.19875 to 2.08012, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 16/50\n",
      "\n",
      "Epoch 00016: val_loss improved from 2.08012 to 2.04154, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 17/50\n",
      "\n",
      "Epoch 00017: val_loss improved from 2.04154 to 1.99384, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 18/50\n",
      "\n",
      "Epoch 00018: val_loss improved from 1.99384 to 1.98161, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 19/50\n",
      "\n",
      "Epoch 00019: val_loss improved from 1.98161 to 1.96328, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 20/50\n",
      "\n",
      "Epoch 00020: val_loss improved from 1.96328 to 1.95002, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 21/50\n",
      "\n",
      "Epoch 00021: val_loss improved from 1.95002 to 1.94926, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 22/50\n",
      "\n",
      "Epoch 00022: val_loss improved from 1.94926 to 1.94096, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 23/50\n",
      "\n",
      "Epoch 00023: val_loss improved from 1.94096 to 1.93857, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 24/50\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1.93857\n",
      "Epoch 25/50\n",
      "\n",
      "Epoch 00025: val_loss improved from 1.93857 to 1.93020, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 26/50\n",
      "\n",
      "Epoch 00026: val_loss improved from 1.93020 to 1.92777, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 27/50\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1.92777\n",
      "Epoch 28/50\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1.92777\n",
      "Epoch 29/50\n",
      "\n",
      "Epoch 00029: val_loss improved from 1.92777 to 1.92004, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 30/50\n",
      "\n",
      "Epoch 00030: val_loss improved from 1.92004 to 1.90843, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 31/50\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 1.90843\n",
      "Epoch 32/50\n",
      "\n",
      "Epoch 00032: val_loss improved from 1.90843 to 1.90649, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 33/50\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1.90649\n",
      "Epoch 34/50\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1.90649\n",
      "Epoch 35/50\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 1.90649\n",
      "Epoch 36/50\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 1.90649\n",
      "Epoch 37/50\n",
      "\n",
      "Epoch 00037: val_loss improved from 1.90649 to 1.90211, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 38/50\n",
      "\n",
      "Epoch 00038: val_loss improved from 1.90211 to 1.90141, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 39/50\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 1.90141\n",
      "Epoch 40/50\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1.90141\n",
      "Epoch 41/50\n",
      "\n",
      "Epoch 00041: val_loss improved from 1.90141 to 1.90016, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 42/50\n",
      "\n",
      "Epoch 00042: val_loss improved from 1.90016 to 1.89679, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 43/50\n",
      "\n",
      "Epoch 00043: val_loss improved from 1.89679 to 1.88895, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 44/50\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 1.88895\n",
      "Epoch 45/50\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 1.88895\n",
      "Epoch 46/50\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 1.88895\n",
      "Epoch 47/50\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 1.88895\n",
      "Epoch 48/50\n",
      "\n",
      "Epoch 00048: val_loss improved from 1.88895 to 1.87941, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 49/50\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 1.87941\n",
      "Epoch 50/50\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 1.87941\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[191]\ttraining's l1: 1.54836\tvalid_0's l1: 1.87416\n",
      "[13:35:39] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation_0-mae:5.27628\tvalidation_1-mae:5.40464\n",
      "Multiple eval metrics have been passed: 'validation_1-mae' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-mae hasn't improved in 1000 rounds.\n",
      "[99]\tvalidation_0-mae:1.91292\tvalidation_1-mae:1.29078\n",
      "Train on 1262 samples, validate on 630 samples\n",
      "Epoch 1/50\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 6.17962, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 2/50\n",
      "\n",
      "Epoch 00002: val_loss improved from 6.17962 to 5.88438, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 3/50\n",
      "\n",
      "Epoch 00003: val_loss improved from 5.88438 to 5.61889, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 4/50\n",
      "\n",
      "Epoch 00004: val_loss improved from 5.61889 to 5.37834, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 5/50\n",
      "\n",
      "Epoch 00005: val_loss improved from 5.37834 to 4.97450, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 6/50\n",
      "\n",
      "Epoch 00006: val_loss improved from 4.97450 to 4.52641, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 7/50\n",
      "\n",
      "Epoch 00007: val_loss improved from 4.52641 to 4.11052, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 8/50\n",
      "\n",
      "Epoch 00008: val_loss improved from 4.11052 to 3.76201, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 9/50\n",
      "\n",
      "Epoch 00009: val_loss improved from 3.76201 to 3.38422, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 10/50\n",
      "\n",
      "Epoch 00010: val_loss improved from 3.38422 to 2.88391, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 11/50\n",
      "\n",
      "Epoch 00011: val_loss improved from 2.88391 to 2.58628, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 12/50\n",
      "\n",
      "Epoch 00012: val_loss improved from 2.58628 to 2.32499, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 13/50\n",
      "\n",
      "Epoch 00013: val_loss improved from 2.32499 to 2.17148, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 14/50\n",
      "\n",
      "Epoch 00014: val_loss improved from 2.17148 to 2.09091, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 15/50\n",
      "\n",
      "Epoch 00015: val_loss improved from 2.09091 to 2.00570, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 16/50\n",
      "\n",
      "Epoch 00016: val_loss improved from 2.00570 to 1.98540, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 17/50\n",
      "\n",
      "Epoch 00017: val_loss improved from 1.98540 to 1.97145, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 18/50\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.97145\n",
      "Epoch 19/50\n",
      "\n",
      "Epoch 00019: val_loss improved from 1.97145 to 1.94656, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 20/50\n",
      "\n",
      "Epoch 00020: val_loss improved from 1.94656 to 1.93703, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 21/50\n",
      "\n",
      "Epoch 00021: val_loss improved from 1.93703 to 1.93182, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 22/50\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1.93182\n",
      "Epoch 23/50\n",
      "\n",
      "Epoch 00023: val_loss improved from 1.93182 to 1.92226, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 24/50\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1.92226\n",
      "Epoch 25/50\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1.92226\n",
      "Epoch 26/50\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1.92226\n",
      "Epoch 27/50\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1.92226\n",
      "Epoch 28/50\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1.92226\n",
      "Epoch 29/50\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1.92226\n",
      "Epoch 30/50\n",
      "\n",
      "Epoch 00030: val_loss improved from 1.92226 to 1.91910, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 31/50\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 1.91910\n",
      "Epoch 32/50\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1.91910\n",
      "Epoch 33/50\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1.91910\n",
      "Epoch 34/50\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1.91910\n",
      "Epoch 35/50\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 1.91910\n",
      "Epoch 36/50\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 1.91910\n",
      "Epoch 37/50\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 1.91910\n",
      "Epoch 38/50\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1.91910\n",
      "Epoch 39/50\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 1.91910\n",
      "Epoch 40/50\n",
      "\n",
      "Epoch 00040: val_loss improved from 1.91910 to 1.91810, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 41/50\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 1.91810\n",
      "Epoch 42/50\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1.91810\n",
      "Epoch 43/50\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 1.91810\n",
      "Epoch 44/50\n",
      "\n",
      "Epoch 00044: val_loss improved from 1.91810 to 1.91189, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 45/50\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 1.91189\n",
      "Epoch 46/50\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 1.91189\n",
      "Epoch 47/50\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 1.91189\n",
      "Epoch 48/50\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 1.91189\n",
      "Epoch 49/50\n",
      "\n",
      "Epoch 00049: val_loss improved from 1.91189 to 1.90799, saving model to .mdl_wtsPL.hdf5\n",
      "Epoch 50/50\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 1.90799\n"
     ]
    }
   ],
   "source": [
    "predictions = pd.DataFrame(0,index=test_scaled.index,columns=[\"lgb0\",\"nn0\",\"xgb0\"])\n",
    "oof = pd.DataFrame(0,index=list(range(0,subtrain_X.shape[0])),columns=[\"lgb0\",\"nn0\",\"xgb0\"])\n",
    "\n",
    "feats = test_scaled.columns.values\n",
    "for exp_no,exp in enumerate(train_experiments):\n",
    "    print(\"train_experiment {}\".format(exp))\n",
    "    mask = eq_groups_data[\"earthquake\"].isin(exp)\n",
    "    subtrain_X = train_X_scaled[mask]\n",
    "    subtrain_y = train_y[mask]\n",
    "    \n",
    "    predictors = [\"lgb\"+str(exp_no),\"nn\"+str(exp_no),\"xgb\"+str(exp_no)]\n",
    "    for p in predictors:\n",
    "        predictions[p] = 0.0\n",
    "    for train_idx,val_idx in folds.split(subtrain_X,subtrain_y):\n",
    "        X_train,y_train = subtrain_X.iloc[train_idx],subtrain_y.iloc[train_idx]\n",
    "        X_val,y_val = subtrain_X.iloc[val_idx],subtrain_y.iloc[val_idx]\n",
    "        \n",
    "        model_lgb = train_lgb(X_val,y_val,X_train,y_train,lgb_params)\n",
    "        \n",
    "        oof.loc[val_idx,predictors[0]] = model_lgb.predict(X_val, num_iteration=model_lgb.best_iteration_)\n",
    "        predictions[predictors[0]] += model_lgb.predict(test_scaled[feats], num_iteration=model_lgb.best_iteration_)\n",
    "        \n",
    "        model_xgb = train_xgb(X_val,y_val,X_train,y_train,xgb_params)\n",
    "        best_iteration = model_xgb.get_booster().best_ntree_limit\n",
    "        oof.loc[val_idx,predictors[1]] = model_xgb.predict(X_val, ntree_limit=best_iteration)\n",
    "        predictions[predictors[1]] += model_xgb.predict(test_scaled[feats], ntree_limit=best_iteration)\n",
    "        \n",
    "        model_nn = train_nn(X_val,y_val,X_train,y_train)\n",
    "        oof.loc[val_idx,predictors[2]] = model_nn.predict(X_val).reshape(len(X_val),)\n",
    "        predictions[predictors[2]] += model_nn.predict(test_scaled[feats]).reshape(len(test_scaled),)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sub = predictions/3\n",
    "final = (0.2*(sub[\"lgb0\"]*0.15+sub[\"xgb0\"]*0.45 +sub[\"nn0\"]*0.4)+\n",
    "         0.2*(sub[\"xgb1\"]*0.45 +sub[\"nn1\"]*0.45)+\n",
    "         0.4*(sub[\"lgb2\"]*0.2+sub[\"xgb2\"]*0.3 +sub[\"nn2\"]*0.5)+\n",
    "         0.2*(sub[\"lgb3\"]*0+sub[\"xgb3\"]*0.6 +sub[\"nn3\"]*0.4)\n",
    "         )\n",
    "submission = pd.DataFrame(\n",
    "    {\"time_to_failure\":final})\n",
    "submission[\"seg_id\"] = test_X.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission.to_csv(\"../../submissions/kfolds/top_solutions/6th-place-sol_part.csv\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_to_failure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2624.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.033628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.259274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.907682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.288298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.388711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.781707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15.053845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       time_to_failure\n",
       "count      2624.000000\n",
       "mean          7.033628\n",
       "std           3.259274\n",
       "min          -1.907682\n",
       "25%           4.288298\n",
       "50%           6.388711\n",
       "75%           9.781707\n",
       "max          15.053845"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f1f70c7d908>]"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1f71c35668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
